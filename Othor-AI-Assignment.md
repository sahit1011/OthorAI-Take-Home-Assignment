# Othor AI â€“ Take-Home Assignment

## ğŸ“‹ Assignment Overview

**Role:** Full Stack AI Developer  
**Experience Level:** 1â€“2 Years  
**Duration:** ~8â€“12 hours  
**Submission:** Public GitHub Repository with README and Video recording

---

## ğŸ¯ Project Description

At Othor AI, we're building intelligent platforms that help users derive insights from data instantly. This assignment evaluates your ability to work with real-world AI backend and frontend challenges.

**Your task:** Build a **Mini AI Analyst as a Service (AaaS)** â€” a microservice that allows users to upload business-related CSVs, automatically analyze the data, train a machine learning model if applicable, and return insights and predictions via an API and dashboard.

This assignment will assess your understanding of:
- Backend development
- Model integration
- System design
- Full-stack thinking

---

## ğŸš€ Objectives

### Part 1: CSV Ingestion and Metadata Engine

Build a **FastAPI backend** that exposes an `/upload` endpoint which:

#### Upload Functionality
- âœ… Accepts `.csv` files up to 50MB
- âœ… Streams the file (avoid full memory load)
- âœ… Infers schema:
  - Column types (categorical, numerical, datetime, boolean)
  - Unique value counts
  - Null percentage
  - Flags for high cardinality and constant columns

#### Profile Endpoint
Implement a `/profile` endpoint to:
- âœ… Return a metadata report for the uploaded file:
  - Outliers
  - Skewness
  - Pairwise correlations
  - Imbalanced columns
  - Data leakage detection (e.g., if a feature is highly correlated with the target)

**Note:** Each uploaded file should be linked to a session token (UUID) for further API access.

---

### Part 2: AutoML Model Pipeline

Create a `/train` endpoint that:

#### Training Features
- âœ… Accepts a column name as the target (optional: infer it if labeled as target, label, etc.)
- âœ… Performs preprocessing:
  - Encode categorical columns
  - Handle missing data
- âœ… Trains a basic classification or regression model:
  - **Recommended:** RandomForest, Logistic Regression, XGBoost

#### Training Output
Returns:
- âœ… Evaluation metrics (accuracy, precision, recall, F1-score or RMSE, RÂ²)
- âœ… Model file path or access token
- âœ… Feature importances or SHAP values (optional)
- âœ… Save the model to disk and allow re-use

---

### Part 3: Inference and Insight Generation

Develop the following endpoints:

#### `/predict` Endpoint
- âœ… Accepts new data and a model token
- âœ… Returns predictions and confidence scores

#### `/summary` Endpoint
Returns a natural-language summary of the data and model:
- âœ… Number of rows/columns
- âœ… Target feature correlation
- âœ… Top predictors
- âœ… Model performance
- ğŸŒŸ **Optional but encouraged:** use a local LLM or transformer model to generate human-readable summaries

---

### Part 4: Frontend Dashboard

Develop a minimal UI using **React/Next.js** or plain HTML+JavaScript that allows:

#### Core Features
- âœ… CSV upload
- âœ… Viewing parsed schema and profiling insights
- âœ… Triggering model training
- âœ… Viewing prediction results in table format
- âœ… Visualizing results (basic charts preferred)

**Important:** The UI should handle loading states and server errors gracefully.

---

## ğŸŒŸ Bonus Features (Optional but Encouraged)

- ğŸ”„ Implement background job processing for model training using Celery or similar
- ğŸ—„ï¸ Store uploaded files and model metadata in PostgreSQL or MongoDB
- ğŸ” Add user authentication with JWT (admin vs viewer access)
- â˜ï¸ Use an S3-compatible bucket for storage
- ğŸ“Š Include visual feature importance charts or clustering analysis
- ğŸ” Add a retry mechanism in inference endpoints for fault tolerance

---

## ğŸ› ï¸ Technical Requirements

### Backend Stack
- **Python 3.9+**
- **FastAPI**
- **Scikit-learn or XGBoost**
- **Pandas, NumPy**

### Frontend Stack
- **React/Next.js** (or plain JS if preferred)

### DevOps
- **Dockerized setup**
- **Basic unit tests** for key endpoints

---

## ğŸ“ Sample Use Case

A business user uploads a product-sales dataset.

**Your system:**
1. ğŸ“Š Profiles the data
2. ğŸ” Detects the schema and target variable (Churn)
3. ğŸ¤– Trains a classification model
4. ğŸ“ˆ Provides a summary and serves predictions via an API and dashboard interface

---

## ğŸ“Š Evaluation Criteria

| **Area** | **Assessment Focus** |
|----------|---------------------|
| **Backend API Design** | Modular FastAPI implementation, best practices |
| **Machine Learning Logic** | Sensible pipelines, model persistence |
| **Data Profiling** | Insightful statistics, smart detection logic |
| **Summarization** | Coherent and human-readable output |
| **Frontend Integration** | Functionality, state handling, responsiveness |
| **Code Quality** | Structure, readability, naming, error handling |
| **Deployment** | Functional Docker setup and environment config |
| **Bonus Implementation** | Innovation, architecture, optional features |

---

## ğŸ“¤ Submission Guidelines

### Repository Requirements
Upload your code to a **public GitHub repository**

### README.md Must Include:
- âœ… Setup instructions
- âœ… How to run/test the app (locally or via Docker)
- âœ… API documentation (basic usage examples)
- âœ… Sample CSVs (if any)
- âœ… Assumptions and limitations
- âœ… Time taken and optional features attempted

### Video Recording
- ğŸ¥ Record a video explaining your approach

---

## ğŸ¯ Success Tips

1. **Start Simple:** Focus on core functionality first
2. **Document Everything:** Clear README and code comments
3. **Test Thoroughly:** Ensure all endpoints work as expected
4. **Handle Errors:** Graceful error handling throughout
5. **Show Your Work:** Explain your design decisions

---

*Good luck with your assignment! We're excited to see your implementation of the Mini AI Analyst as a Service.*
