# ğŸš€ Othor AI - Mini AI Analyst as a Service

A full-stack application that allows users to upload CSV files, automatically analyze data, train machine learning models, and generate predictions through an intuitive web interface.

## ğŸ“‹ Features

### Core Features
- ğŸ“Š **CSV Upload & Processing** - Upload files up to 50MB with streaming processing
- ğŸ” **Data Profiling** - Automatic schema inference, statistical analysis, and data quality assessment
- ğŸ¤– **AutoML Pipeline** - Automated preprocessing, model training, and evaluation
- ğŸ“ˆ **Predictions** - Generate predictions with confidence scores
- ğŸ“ **Natural Language Summaries** - Human-readable insights and recommendations

### Technical Features
- âš¡ **FastAPI Backend** - High-performance API with automatic documentation
- ğŸ¨ **React/Next.js Frontend** - Modern, responsive user interface
- ğŸ³ **Docker Support** - Containerized deployment
- ğŸ§ª **Comprehensive Testing** - Unit and integration tests
- ğŸ“š **API Documentation** - Interactive Swagger/OpenAPI docs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Storage       â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (File System) â”‚
â”‚   Port: 3000    â”‚    â”‚   Port: 8000    â”‚    â”‚   + ML Models   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- **Git** (for cloning the repository)
- **Docker & Docker Compose** (for containerized deployment)

### ğŸ³ Docker Deployment (Recommended for Recruiters)

**The easiest way to run the application - no need to install Python, Node.js, or manage dependencies!**

#### For Windows Users:
```bash
# Clone the repository
git clone https://github.com/sahit1011/OthorAI-Take-Home-Assignment.git
cd OthorAI-Take-Home-Assignment

# Run the startup script
start-docker.bat
```

#### For Mac/Linux Users:
```bash
# Clone the repository
git clone https://github.com/sahit1011/OthorAI-Take-Home-Assignment.git
cd OthorAI-Take-Home-Assignment

# Make the script executable and run it
chmod +x start-docker.sh
./start-docker.sh
```

#### Manual Docker Commands:
```bash
# Clone the repository
git clone https://github.com/sahit1011/OthorAI-Take-Home-Assignment.git
cd OthorAI-Take-Home-Assignment

# Create required directories
mkdir -p data/uploads data/models logs

# Start all services with Docker
docker-compose up --build

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8001
# API Docs: http://localhost:8001/docs
```

### ğŸ’» Local Development Setup (For Developers)

**Prerequisites:** Python 3.9+, Node.js 16+

```bash
# Clone the repository
git clone https://github.com/sahit1011/OthorAI-Take-Home-Assignment.git
cd OthorAI-Take-Home-Assignment

# Backend setup
cd backend
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies and run
pip install -r requirements.txt
uvicorn app.main:app --reload --host 127.0.0.1 --port 8001

# Frontend setup (new terminal)
cd frontend
npm install
npm run dev

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8001
# API Docs: http://localhost:8001/docs
```

## ğŸ“– Usage

### 1. Upload CSV File
- Navigate to http://localhost:3000
- Upload a CSV file (max 50MB)
- Get instant schema analysis and data profiling

### 2. Analyze Data
- View statistical summaries
- Explore correlations and data quality metrics
- Identify potential issues and patterns

### 3. Train Model
- Select target column
- Choose algorithm (Random Forest, XGBoost, Logistic Regression)
- Get evaluation metrics and feature importance

### 4. Make Predictions
- Input new data points
- Get predictions with confidence scores
- Download results

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/upload` | Upload CSV file |
| GET | `/profile/{session_id}` | Get data profile |
| POST | `/train` | Train ML model |
| POST | `/predict` | Make predictions |
| GET | `/summary/{model_id}` | Get model summary |

Full API documentation: http://localhost:8000/docs

## ğŸ§ª Testing

### Backend Tests
```bash
cd backend
pytest tests/ -v --cov=app
```

### Frontend Tests
```bash
cd frontend
npm test
```

## ğŸ“ Project Structure

```
othor-ai-assignment/
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”‚   â”œâ”€â”€ core/           # Core business logic
â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic models
â”‚   â”‚   â””â”€â”€ utils/          # Utilities
â”‚   â”œâ”€â”€ tests/              # Backend tests
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ pages/          # Next.js pages
â”‚   â”‚   â”œâ”€â”€ services/       # API services
â”‚   â”‚   â””â”€â”€ styles/         # CSS styles
â”‚   â””â”€â”€ package.json        # Node dependencies
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ uploads/            # Uploaded files
â”‚   â”œâ”€â”€ models/             # Trained models
â”‚   â””â”€â”€ samples/            # Sample datasets
â””â”€â”€ docker-compose.yml      # Multi-container setup
```

## ğŸ”§ Configuration

### Environment Variables

#### Backend (.env)
```bash
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True
MAX_FILE_SIZE=52428800
UPLOAD_DIR=./data/uploads
MODEL_DIR=./data/models
SESSION_TIMEOUT=86400
```

#### Frontend (.env.local)
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_MAX_FILE_SIZE=52428800
```

## ğŸ¯ Sample Datasets

The `data/samples/` directory contains example CSV files for testing:
- `sales_data.csv` - Sales regression example
- `customer_churn.csv` - Classification example
- `product_analysis.csv` - General analysis example

## ğŸš€ Deployment

### Production Deployment
```bash
# Build production images
docker-compose -f docker-compose.prod.yml up --build

# Or deploy to cloud platforms
# (AWS, GCP, Azure, Heroku, etc.)
```

## ğŸ”’ Security Features

- File type validation (CSV only)
- File size limits (50MB max)
- Input sanitization and validation
- Session-based authentication
- Error handling without information leakage

## ğŸ“Š Performance

- Streaming file processing for large datasets
- Async API endpoints for better concurrency
- Optimized ML pipelines
- Caching for repeated operations

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

- Check the documentation in `docs/`
- Review API docs at `/docs` endpoint
- Open an issue for bugs or feature requests

---

**Built with â¤ï¸ for the Othor AI Take-Home Assignment**
